{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b517ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataframe(Train and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "Dataframe created\n",
      "                          image  label\n",
      "0      images/train\\angry\\0.jpg  angry\n",
      "1      images/train\\angry\\1.jpg  angry\n",
      "2     images/train\\angry\\10.jpg  angry\n",
      "3  images/train\\angry\\10002.jpg  angry\n",
      "4  images/train\\angry\\10016.jpg  angry\n"
     ]
    }
   ],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    print(\"Dataframe created\")\n",
    "    return image_paths,labels\n",
    "\n",
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "Dataframe created\n",
      "                         image  label\n",
      "0  images/test\\angry\\10052.jpg  angry\n",
      "1  images/test\\angry\\10065.jpg  angry\n",
      "2  images/test\\angry\\10079.jpg  angry\n",
      "3  images/test\\angry\\10095.jpg  angry\n",
      "4  images/test\\angry\\10121.jpg  angry\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde554cfd89b42bcada0d0cd6f128861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacb8b1f1cd84559b2b425dd1fe7d9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "\n",
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  5/226 [..............................] - ETA: 3:30 - loss: 1.8916 - accuracy: 0.2078"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32ms:\\SWE_STUDIES\\Github Projects\\Facial_Text_EmotionDetector_EmojiGenerator\\Train_Model_Facial_Emotion.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/SWE_STUDIES/Github%20Projects/Facial_Text_EmotionDetector_EmojiGenerator/Train_Model_Facial_Emotion.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m7\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/SWE_STUDIES/Github%20Projects/Facial_Text_EmotionDetector_EmojiGenerator/Train_Model_Facial_Emotion.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/SWE_STUDIES/Github%20Projects/Facial_Text_EmotionDetector_EmojiGenerator/Train_Model_Facial_Emotion.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49m x_train,y \u001b[39m=\u001b[39;49m y_train, batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m, epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (x_test,y_test))\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\TahlilMahfuz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy' )\n",
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 10, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"facialemotionmodel.h5\")\n",
    "\n",
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "\n",
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of happy\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fedde96190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/happy/64.jpg'\n",
    "print(\"original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
